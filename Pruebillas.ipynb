{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8d876d-277d-498d-8ce2-c99dd7f9f699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from statsmodels) (1.24.4)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "380dcb0a-74b3-4f83-a62e-fa5287b8c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, make_scorer, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from backbone.probability_transformer import ProbabilityTransformer \n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from backbone.utils import load_function\n",
    "from typing import Tuple\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae82f4b-f988-4c94-9c7c-f5fe2ce4ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la volatilidad diaria\n",
    "def get_daily_volatility(close_prices, span=100):\n",
    "    returns = close_prices.pct_change()\n",
    "    volatility = returns.ewm(span=span).std()\n",
    "    return volatility\n",
    "\n",
    "# Función para aplicar el filtro CUSUM\n",
    "def apply_cusum_filter(raw_price, threshold):\n",
    "    \"\"\"\n",
    "    :param raw_price: (series) of close prices.\n",
    "    :param threshold: (float) when the abs(change) is larger than the threshold, the\n",
    "    function captures it as an event.\n",
    "    :return: (datetime index vector) vector of datetimes when the events occurred. This is used later to sample.\n",
    "    \"\"\"\n",
    "    print('Applying Symmetric CUSUM filter.')\n",
    "\n",
    "    t_events = []\n",
    "    s_pos = 0\n",
    "    s_neg = 0\n",
    "\n",
    "    # log returns\n",
    "    diff = np.log(raw_price).diff().dropna()\n",
    "\n",
    "    # Get event time stamps for the entire series\n",
    "    for i in tqdm(diff.index[1:]):\n",
    "        pos = float(s_pos + diff.loc[i])\n",
    "        neg = float(s_neg + diff.loc[i])\n",
    "        s_pos = max(0.0, pos)\n",
    "        s_neg = min(0.0, neg)\n",
    "\n",
    "        if s_neg < -threshold:\n",
    "            s_neg = 0\n",
    "            t_events.append(i)\n",
    "\n",
    "        elif s_pos > threshold:\n",
    "            s_pos = 0\n",
    "            t_events.append(i)\n",
    "\n",
    "    event_timestamps = pd.DatetimeIndex(t_events)\n",
    "    return event_timestamps\n",
    "\n",
    "# Función para aplicar el método de triple barrera con filtro CUSUM\n",
    "def apply_triple_barrier(\n",
    "    close_prices, \n",
    "    max_prices, \n",
    "    min_prices, \n",
    "    take_profit_in_pips, \n",
    "    stop_loss_in_pips, \n",
    "    side,\n",
    "    max_holding_period=50, \n",
    "    pip_size=0.0001\n",
    "    ):\n",
    "\n",
    "    barriers = []\n",
    "\n",
    "    for index in range(len(close_prices)):\n",
    "        if side[index] == 1:\n",
    "            # Para una señal de compra\n",
    "            upper_barrier_level = close_prices[index] * (1 + (take_profit_in_pips * pip_size))\n",
    "            lower_barrier_level = close_prices[index] * (1 - (stop_loss_in_pips * pip_size))\n",
    "        elif side[index] == -1:\n",
    "            # Para una señal de venta\n",
    "            upper_barrier_level = close_prices[index] * (1 + (stop_loss_in_pips * pip_size))\n",
    "            lower_barrier_level = close_prices[index] * (1 - (take_profit_in_pips * pip_size))\n",
    "        else:\n",
    "            # Si no hay señal, saltar al siguiente índice\n",
    "            continue\n",
    "        \n",
    "        # Evaluar los precios futuros dentro del período máximo de mantenimiento\n",
    "        for j in range(index + 1, min(index + max_holding_period, len(close_prices))):\n",
    "            if side[index] == 1:\n",
    "                # Señal de compra: tomar ganancias si se alcanza la barrera superior\n",
    "                if close_prices[j] >= upper_barrier_level or max_prices[j] >= upper_barrier_level:\n",
    "                    barriers.append((index, 1))  # Etiqueta 1 para toma de ganancias\n",
    "                    break\n",
    "                elif close_prices[j] <= lower_barrier_level or min_prices[j] <= lower_barrier_level:\n",
    "                    barriers.append((index, 0))  # Etiqueta 0 para stop-loss\n",
    "                    break\n",
    "            elif side[index] == -1:\n",
    "                # Señal de venta: tomar ganancias si se alcanza la barrera inferior\n",
    "                if close_prices[j] <= lower_barrier_level or min_prices[j] <= lower_barrier_level:\n",
    "                    barriers.append((index, 1))  # Etiqueta 1 para toma de ganancias\n",
    "                    break\n",
    "                elif close_prices[j] >= upper_barrier_level or max_prices[j] >= upper_barrier_level:\n",
    "                    barriers.append((index, 0))  # Etiqueta 0 para stop-loss\n",
    "                    break\n",
    "        else:\n",
    "            barriers.append((index, 2))  # Etiqueta 2 si no se alcanza ninguna barrera\n",
    "    \n",
    "    # Revisar los eventos etiquetados como 2 para determinar si son ganancias o pérdidas\n",
    "    for idx, (event_index, label) in enumerate(barriers):\n",
    "        if label == 2:\n",
    "            # Determinar si el precio final fue una ganancia o una pérdida\n",
    "            final_price = close_prices[min(event_index + max_holding_period, len(close_prices) - 1)]\n",
    "            initial_price = close_prices[event_index]\n",
    "            \n",
    "            if side[event_index] == 1:\n",
    "                # Para una señal de compra\n",
    "                if final_price >= initial_price:\n",
    "                    barriers[idx] = (event_index, 1)  # Etiqueta 1 para toma de ganancias\n",
    "                elif final_price < initial_price:\n",
    "                    barriers[idx] = (event_index, 0)  # Etiqueta 0 para stop-loss\n",
    "            elif side[event_index] == -1:\n",
    "                # Para una señal de venta\n",
    "                if final_price <= initial_price:\n",
    "                    barriers[idx] = (event_index, 1)  # Etiqueta 1 para toma de ganancias\n",
    "                elif final_price > initial_price:\n",
    "                    barriers[idx] = (event_index, 0)  # Etiqueta 0 para stop-loss\n",
    "\n",
    "    return barriers\n",
    "\n",
    "# Función principal que usa el método de triple barrera con filtro CUSUM\n",
    "def triple_barrier_labeling(\n",
    "        close_prices, \n",
    "        max_prices, \n",
    "        min_prices,  \n",
    "        take_profit_in_pips, \n",
    "        stop_loss_in_pips, \n",
    "        side,\n",
    "        max_holding_period=50, \n",
    "        pip_size=0.0001,\n",
    "    ):\n",
    "\n",
    "    \n",
    "    labels = apply_triple_barrier(\n",
    "        close_prices,\n",
    "        max_prices,\n",
    "        min_prices,\n",
    "        take_profit_in_pips, \n",
    "        stop_loss_in_pips, \n",
    "        side,\n",
    "        max_holding_period, \n",
    "        pip_size\n",
    "    )\n",
    "    \n",
    "    target = [label for _, label in labels]\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635ce9b-b3c3-4b67-907a-ce038e45f47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f2d5ff2-462d-4799-b21c-b33698d0ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando target\n",
      "side\n",
      " 1.0    181\n",
      "-1.0    180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "symbols_path = './backbone/data/backtest/symbols/EURUSD.csv'\n",
    "df = pd.read_csv(symbols_path)\n",
    "\n",
    "print('Creando target')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(by='Date')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "instrument = df.copy()\n",
    "# compute bband sides\n",
    "\n",
    "instrument['side'] = np.nan\n",
    "\n",
    "# long_signals = (instrument['Close'] <= instrument['lower_bband'])\n",
    "# short_signals = (instrument['Close'] >= instrument['upper_bband'])\n",
    "# instrument.loc[long_signals, 'side'] = 1\n",
    "# instrument.loc[short_signals, 'side'] = -1\n",
    "\n",
    "# compute macd sides\n",
    "# long_signals = (instrument['macd'] > instrument['macdsignal']) & (instrument['macd'].shift(1) <= instrument['macdsignal'].shift(1))\n",
    "# instrument.loc[long_signals, 'side'] = 1\n",
    "# short_signals = (instrument['macd'] < instrument['macdsignal']) & (instrument['macd'].shift(1) >= instrument['macdsignal'].shift(1))\n",
    "# instrument.loc[short_signals, 'side'] = -1\n",
    "\n",
    "cycle, trend = hpfilter(instrument['Close'], lamb=1000)\n",
    "instrument['trend'] = trend\n",
    "instrument['SMA20'] = instrument['trend'].rolling(window=20).mean()\n",
    "# instrument['SMA200'] = instrument['trend'].rolling(window=200).mean()\n",
    "long_signals = (instrument['trend'] > instrument['SMA20']) & (instrument['trend'].shift(1) <= instrument['SMA20'].shift(1))\n",
    "short_signals = (instrument['trend'] < instrument['SMA20']) & (instrument['trend'].shift(1) >= instrument['SMA20'].shift(1))\n",
    "instrument.loc[long_signals, 'side'] = 1\n",
    "instrument.loc[short_signals, 'side'] = -1\n",
    "\n",
    "# Remove Look ahead biase by lagging the signal\n",
    "instrument['side'] = instrument['side'].shift(1)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "# volatility = get_daily_volatility(instrument.Close, span=120)\n",
    "\n",
    "# cusum_events = apply_cusum_filter(instrument.Close, threshold=volatility.mean()*0.25)\n",
    "\n",
    "# instrument = instrument.loc[cusum_events]\n",
    "\n",
    "instrument.dropna(inplace=True)\n",
    "\n",
    "print(instrument.side.value_counts())\n",
    "\n",
    "instrument['target'] = triple_barrier_labeling(\n",
    "    close_prices=instrument['Close'], \n",
    "    min_prices=instrument['Low'], \n",
    "    max_prices=instrument['High'], \n",
    "    take_profit_in_pips=30, \n",
    "    stop_loss_in_pips=15, \n",
    "    max_holding_period=24, \n",
    "    pip_size=0.0001,\n",
    "    side=instrument['side']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe630e56-3ceb-41b8-a288-4c8a91116b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    238\n",
       "0    123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instrument['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53ba3baa-329a-444c-a9be-8f43cefad3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[instrument.index, 'side'] = instrument.side\n",
    "df.loc[instrument.index, 'target'] = instrument.target\n",
    "df.fillna(0, inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5cfb966-cadd-4bad-961d-f9780f2c65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.Date.dt.year\n",
    "df['month'] = df.Date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f399348-5279-444f-a2e3-b32a2daee195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>side</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2019</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">2020</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">2021</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target\n",
       "year month side        \n",
       "2019 9     -1.0       2\n",
       "            1.0       2\n",
       "     10    -1.0       6\n",
       "            1.0       6\n",
       "     11    -1.0       6\n",
       "            1.0       7\n",
       "     12    -1.0       6\n",
       "            1.0       6\n",
       "2020 1     -1.0       6\n",
       "            1.0       6\n",
       "     2     -1.0       4\n",
       "            1.0       4\n",
       "     3     -1.0       5\n",
       "            1.0       5\n",
       "     4     -1.0       8\n",
       "            1.0       8\n",
       "     5     -1.0       4\n",
       "            1.0       4\n",
       "     6     -1.0       5\n",
       "            1.0       4\n",
       "     7     -1.0       6\n",
       "            1.0       6\n",
       "     8     -1.0       8\n",
       "            1.0       9\n",
       "     9     -1.0       7\n",
       "            1.0       6\n",
       "     10    -1.0       8\n",
       "            1.0       8\n",
       "     11    -1.0       7\n",
       "            1.0       7\n",
       "     12    -1.0       8\n",
       "            1.0       8\n",
       "2021 1     -1.0       6\n",
       "            1.0       7\n",
       "     2     -1.0       6\n",
       "            1.0       5\n",
       "     3     -1.0       5\n",
       "            1.0       6\n",
       "     4     -1.0       9\n",
       "            1.0       8\n",
       "     5     -1.0       6\n",
       "            1.0       7\n",
       "     6     -1.0       7\n",
       "            1.0       6\n",
       "     7     -1.0       6\n",
       "            1.0       6\n",
       "     8     -1.0       6\n",
       "            1.0       6\n",
       "     9     -1.0       7\n",
       "            1.0       7\n",
       "     10    -1.0       8\n",
       "            1.0       8\n",
       "     11    -1.0       7\n",
       "            1.0       8\n",
       "     12    -1.0      11\n",
       "            1.0      11"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[df['side'] != 0].groupby(by=['year','month', 'side']).agg({'target':'count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31defd7-a736-4c45-9160-88d1252605db",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef3b6ac4-58ad-4d10-a1d8-09ed03993fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6592797783933518"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instrument[(instrument.side != 0) & (instrument.target==1)].shape[0] / instrument[(instrument.side!=0)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2bb6a3-771d-45d9-8285-77bf2aeb17c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a394a-f02a-433f-b807-c201afd7b7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7a6fa-492f-4ac0-8c8b-fa5826219f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e2b75-16ef-4972-ae54-df9a77cb01e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ab367-8f7b-4048-b855-38fe386db2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf98af3-365e-4eea-9c69-1e9c47b6832b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e556fda-bbaa-4b0f-b142-27cd4936df53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6c7f86-0376-4e63-ae59-42f2b30be587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# periods_forward = 5\n",
    "\n",
    "# tickers = ['EURUSD']\n",
    "# symbols_path = './backbone/data/backtest/symbols'\n",
    "# instruments = {}\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# for ticker in tickers:\n",
    "#     instruments[ticker] = pd.read_csv(os.path.join(symbols_path, f'{ticker}.csv'))\n",
    "  \n",
    "#     instruments[ticker]['ticker'] = ticker\n",
    "  \n",
    "#     print('Creando target')\n",
    "   \n",
    "#     instruments[ticker] = instruments[ticker].sort_values(by='Date')\n",
    "\n",
    "#     instruments[ticker]['target'] = triple_barrier_labeling(instruments[ticker], upper_barrier=0.015, lower_barrier=0.015, max_holding_period=48, span=100)\n",
    "    \n",
    "#     df = pd.concat([\n",
    "#         df,\n",
    "#         instruments[ticker]\n",
    "#     ])\n",
    "\n",
    "#     df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %H:00:00')\n",
    "\n",
    "#     df = df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11a3a322-05e6-4f04-b6a7-5c0cb1fec910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1.0    11\n",
       "0.0     9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_format = '%Y-%m-%d %H:00:00'\n",
    "window = 5760\n",
    "\n",
    "actual_date = datetime(2021,8,1,0,0,0)\n",
    "\n",
    "date_to = actual_date - timedelta(hours=24+1) \n",
    "date_from = date_to - timedelta(hours=window)\n",
    "\n",
    "date_from_test = actual_date\n",
    "date_to_test = date_from_test + timedelta(hours=48)\n",
    "\n",
    "date_from_str = date_from.strftime(date_format)\n",
    "date_to_str = date_to.strftime(date_format)\n",
    "date_from_test_str = date_from_test.strftime(date_format)\n",
    "date_to_test_str = date_to_test.strftime(date_format)\n",
    "\n",
    "\n",
    "train = df[(df['Date']>date_from_str) & (df['Date']<date_to_str) & (df.side != 0)]\n",
    "test = df[(df['Date']>date_from_test_str) & (df['Date']<date_to_test_str) & (df.side != 0)]\n",
    "\n",
    "# Inicio undersampling\n",
    "# class_0 = train[train['target']==0]\n",
    "# class_2 = train[train['target']==2]\n",
    "# avg_examples = (class_0.shape[0] + class_2.shape[0]) / 2\n",
    "# class_1 = train[train['target']==1].tail(int(avg_examples)).sample(frac=1)\n",
    "\n",
    "# train = pd.concat([class_0, class_1, class_2])\n",
    "# fin undersampling\n",
    "\n",
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c88a0bf6-7612-454d-96f6-72867b043468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f69d55c-5d68-4bab-b6b6-725d3d5011bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'stacking' for estimator Pipeline(steps=[('scaler', StandardScaler()),\n                ('prob_transf',\n                 ProbabilityTransformer(model=XGBClassifier(base_score=None,\n                                                            booster=None,\n                                                            callbacks=None,\n                                                            colsample_bylevel=None,\n                                                            colsample_bynode=None,\n                                                            colsample_bytree=None,\n                                                            device=None,\n                                                            early_stopping_rounds=None,\n                                                            enable_categorical=False,\n                                                            eval_metric=None,\n                                                            feature_types=None,\n                                                            gamma=None,\n                                                            grow_policy=None,\n                                                            importanc...\n                                                            interaction_constraints=None,\n                                                            learning_rate=None,\n                                                            max_bin=None,\n                                                            max_cat_threshold=None,\n                                                            max_cat_to_onehot=None,\n                                                            max_delta_step=None,\n                                                            max_depth=None,\n                                                            max_leaves=None,\n                                                            min_child_weight=None,\n                                                            missing=nan,\n                                                            monotone_constraints=None,\n                                                            multi_strategy=None,\n                                                            n_estimators=None,\n                                                            n_jobs=None,\n                                                            num_parallel_tree=None,\n                                                            random_state=None, ...))),\n                ('log_reg', LogisticRegression(max_iter=1000))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 717, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\pipeline.py\", line 222, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 68, in _set_params\n    super().set_params(**params)\n  File \"c:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\base.py\", line 230, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'stacking' for estimator Pipeline(steps=[('scaler', StandardScaler()),\n                ('prob_transf',\n                 ProbabilityTransformer(model=XGBClassifier(base_score=None,\n                                                            booster=None,\n                                                            callbacks=None,\n                                                            colsample_bylevel=None,\n                                                            colsample_bynode=None,\n                                                            colsample_bytree=None,\n                                                            device=None,\n                                                            early_stopping_rounds=None,\n                                                            enable_categorical=False,\n                                                            eval_metric=None,\n                                                            feature_types=None,\n                                                            gamma=None,\n                                                            grow_policy=None,\n                                                            importanc...\n                                                            interaction_constraints=None,\n                                                            learning_rate=None,\n                                                            max_bin=None,\n                                                            max_cat_threshold=None,\n                                                            max_cat_to_onehot=None,\n                                                            max_delta_step=None,\n                                                            max_depth=None,\n                                                            max_leaves=None,\n                                                            min_child_weight=None,\n                                                            missing=nan,\n                                                            monotone_constraints=None,\n                                                            multi_strategy=None,\n                                                            n_estimators=None,\n                                                            n_jobs=None,\n                                                            num_parallel_tree=None,\n                                                            random_state=None, ...))),\n                ('log_reg', LogisticRegression(max_iter=1000))]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 27\u001b[0m\n\u001b[0;32m     17\u001b[0m stratified_kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mn_splits, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     19\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     20\u001b[0m     pipe,\n\u001b[0;32m     21\u001b[0m     param_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     scoring\u001b[38;5;241m=\u001b[39mmake_scorer(precision_score, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\saidj\\onedrive\\documentos\\projects\\forex_ml_bot\\forex_ml_bot\\mtvenv\\lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'stacking' for estimator Pipeline(steps=[('scaler', StandardScaler()),\n                ('prob_transf',\n                 ProbabilityTransformer(model=XGBClassifier(base_score=None,\n                                                            booster=None,\n                                                            callbacks=None,\n                                                            colsample_bylevel=None,\n                                                            colsample_bynode=None,\n                                                            colsample_bytree=None,\n                                                            device=None,\n                                                            early_stopping_rounds=None,\n                                                            enable_categorical=False,\n                                                            eval_metric=None,\n                                                            feature_types=None,\n                                                            gamma=None,\n                                                            grow_policy=None,\n                                                            importanc...\n                                                            interaction_constraints=None,\n                                                            learning_rate=None,\n                                                            max_bin=None,\n                                                            max_cat_threshold=None,\n                                                            max_cat_to_onehot=None,\n                                                            max_delta_step=None,\n                                                            max_depth=None,\n                                                            max_leaves=None,\n                                                            min_child_weight=None,\n                                                            missing=nan,\n                                                            monotone_constraints=None,\n                                                            multi_strategy=None,\n                                                            n_estimators=None,\n                                                            n_jobs=None,\n                                                            num_parallel_tree=None,\n                                                            random_state=None, ...))),\n                ('log_reg', LogisticRegression(max_iter=1000))]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "log_reg = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000)\n",
    "model = XGBClassifier()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('prob_transf', ProbabilityTransformer(model)),\n",
    "    ('log_reg', log_reg)\n",
    "])\n",
    "\n",
    "with open('configs/model_config.yml', 'r') as file:\n",
    "    model_configs = yaml.safe_load(file)\n",
    "\n",
    "param_grid = model_configs['gradient_boosting']['param_grid']\n",
    "\n",
    "n_splits = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=stratified_kfold,\n",
    "    scoring=make_scorer(precision_score, average='weighted')\n",
    ")\n",
    "\n",
    "search.fit(train.drop(columns=['target', 'Date']), train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1bbcf-2dec-4aab-bf2a-957627c2533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop(columns=['target', 'Date', 'ticker'])\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f21f8-867d-4a91-b07e-97e9b776c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0efc20-5291-42ff-b9e6-9d07af4ab09b",
   "metadata": {},
   "source": [
    "# Train performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b040a9-d923-4ffb-b290-094389d44588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_\n",
    "\n",
    "predictions = pipeline.predict_proba(train.drop(columns=['target', 'Date', 'ticker']))\n",
    "max_probabilities = np.max(predictions, axis=1)\n",
    "max_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "precision = precision_score(train.target, max_indices, average='weighted')\n",
    "recall = recall_score(train.target, max_indices, average='weighted')\n",
    "f1 = f1_score(train.target, max_indices, average='weighted')\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1) \n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(train.target, max_indices, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede6b3f-998d-4554-ba77-039fd3815f91",
   "metadata": {},
   "source": [
    "# Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554a318-f240-4f45-aa26-9f3caf24fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict_proba(test.drop(columns=['target', 'Date', 'ticker']))\n",
    "max_probabilities = np.max(predictions, axis=1)\n",
    "max_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "precision = precision_score(test.target, max_indices, average='weighted')\n",
    "recall = recall_score(test.target, max_indices, average='weighted')\n",
    "f1 = f1_score(test.target, max_indices, average='weighted')\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)\n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(test.target, max_indices, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a7fcd-49ed-467d-895d-d5f0bf012016",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_path = './backbone/data/backtest/symbols/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59297e8-74bb-496c-8272-2e940d9c6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4928e6-f88b-455a-a1ad-072f7c7b8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(symbols_path)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa272633-5ba0-4a27-bb3e-02428cdc6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['target']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43bec9-18fc-496a-93d7-1ccf00e625fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
